{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 1: SETUP & INSTALL (Kaggle Version)\n# ============================================\nimport os\nimport sys\n\n# Install required packages\n!pip install roboflow -q\n!pip install segmentation-models-pytorch -q\n!pip install albumentations -q\n!pip install gradio -q\n!pip install pycocotools -q\n!pip install torchmetrics -q\n\nprint(\"‚úÖ Kaggle setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:58:31.760269Z","iopub.execute_input":"2025-12-05T17:58:31.760492Z","iopub.status.idle":"2025-12-05T18:00:13.573502Z","shell.execute_reply.started":"2025-12-05T17:58:31.760464Z","shell.execute_reply":"2025-12-05T18:00:13.572334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 2: DOWNLOAD DATASET\n# ============================================\nfrom roboflow import Roboflow\n\n# Your API key\nrf = Roboflow(api_key=\"FoHdZwbhLlvtF4Xo4zdZ\")\nproject = rf.workspace(\"studentdatasets\").project(\"microscopy-cell-segmentation\")\nversion = project.version(21)\ndataset = version.download(\"coco-segmentation\")\n\nprint(\"‚úÖ Dataset downloaded!\")\ndataset_path = dataset.location","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:03:45.222925Z","iopub.execute_input":"2025-12-05T18:03:45.223337Z","iopub.status.idle":"2025-12-05T18:03:55.658144Z","shell.execute_reply.started":"2025-12-05T18:03:45.223303Z","shell.execute_reply":"2025-12-05T18:03:55.657278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 3: IMPORTS & GPU SETUP\n# ============================================\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport segmentation_models_pytorch as smp\nimport pandas as pd\nimport torch.nn.functional as F\nfrom torchmetrics.classification import BinaryJaccardIndex, BinaryF1Score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üöÄ Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    \n# Create output directory\noutput_dir = '/kaggle/working/cell_segmentation_improved'\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"üìÅ Output directory: {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:04:10.293944Z","iopub.execute_input":"2025-12-05T18:04:10.294626Z","iopub.status.idle":"2025-12-05T18:04:25.394253Z","shell.execute_reply.started":"2025-12-05T18:04:10.294600Z","shell.execute_reply":"2025-12-05T18:04:25.393448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 4: IMPROVED DATASET CLASS\n# ============================================\nclass CellSegmentationDataset(Dataset):\n    \"\"\"Improved dataset with better augmentation\"\"\"\n    def __init__(self, json_path, img_dir, img_size=512, augment=True):\n        with open(json_path) as f:\n            data = json.load(f)\n        \n        self.images = data['images']\n        self.annotations = data['annotations']\n        self.img_dir = img_dir\n        self.img_size = img_size\n        self.augment = augment\n        \n        # Create annotation mapping\n        self.ann_map = {}\n        for ann in self.annotations:\n            img_id = ann['image_id']\n            if img_id not in self.ann_map:\n                self.ann_map[img_id] = []\n            self.ann_map[img_id].append(ann)\n        \n        self.image_paths = [os.path.join(img_dir, img['file_name']) for img in self.images]\n        \n        # Enhanced augmentations for microscopy\n        if augment:\n            self.transform = A.Compose([\n                A.Resize(img_size, img_size, always_apply=True),\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.RandomBrightnessContrast(p=0.3, brightness_limit=0.1, contrast_limit=0.1),\n                A.GaussianBlur(p=0.1, blur_limit=(3, 7)),\n                A.GaussNoise(p=0.1, var_limit=(10.0, 50.0)),\n                A.ElasticTransform(p=0.2, alpha=1, sigma=50, alpha_affine=50),\n                A.CoarseDropout(p=0.1, max_holes=8, max_height=32, max_width=32, fill_value=0),\n                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n                ToTensorV2(),\n            ])\n        else:\n            self.transform = A.Compose([\n                A.Resize(img_size, img_size, always_apply=True),\n                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n                ToTensorV2(),\n            ])\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_info = self.images[idx]\n        \n        # Create mask\n        mask = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n        \n        if img_info['id'] in self.ann_map:\n            for ann in self.ann_map[img_info['id']]:\n                for seg in ann['segmentation']:\n                    pts = np.array(seg).reshape(-1, 2)\n                    if len(pts) > 0:\n                        # Preserve aspect ratio\n                        pts[:, 0] = pts[:, 0] * self.img_size / img_info['width']\n                        pts[:, 1] = pts[:, 1] * self.img_size / img_info['height']\n                        pts = pts.astype(np.int32)\n                        cv2.fillPoly(mask, [pts], 1)\n        \n        transformed = self.transform(image=img, mask=mask)\n        img_tensor = transformed['image']\n        mask_tensor = transformed['mask']\n        \n        return img_tensor, mask_tensor.float()\n\n# Create datasets\nprint(\"üìä Creating datasets...\")\ntrain_dataset = CellSegmentationDataset(\n    os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"),\n    os.path.join(dataset_path, \"train\"),\n    augment=True\n)\n\nval_dataset = CellSegmentationDataset(\n    os.path.join(dataset_path, \"valid\", \"_annotations.coco.json\"),\n    os.path.join(dataset_path, \"valid\"),\n    augment=False\n)\n\ntest_dataset = CellSegmentationDataset(\n    os.path.join(dataset_path, \"test\", \"_annotations.coco.json\"),\n    os.path.join(dataset_path, \"test\"),\n    augment=False\n)\n\nprint(f\"‚úÖ Datasets created!\")\nprint(f\"Train: {len(train_dataset)} images\")\nprint(f\"Validation: {len(val_dataset)} images\")\nprint(f\"Test: {len(test_dataset)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:05:05.565688Z","iopub.execute_input":"2025-12-05T18:05:05.566646Z","iopub.status.idle":"2025-12-05T18:05:06.650555Z","shell.execute_reply.started":"2025-12-05T18:05:05.566617Z","shell.execute_reply":"2025-12-05T18:05:06.649835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 5: CREATE 7 IMPROVED MODELS\n# ============================================\nprint(\"üß† CREATING 7 IMPROVED MODELS...\")\nprint(\"=\"*50)\n\n# 1. U-Net with EfficientNet-B4 (Best from your results)\nprint(\"1. Creating U-Net EfficientNet-B4...\")\nmodel1 = smp.Unet(\n    encoder_name=\"timm-efficientnet-b4\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None,\n    decoder_attention_type=\"scse\",\n    decoder_dropout=0.3\n).to(device)\n\n# 2. DeepLabV3+ with ResNet50 (Improved)\nprint(\"2. Creating DeepLabV3+ ResNet50...\")\nmodel2 = smp.DeepLabV3Plus(\n    encoder_name=\"resnet50\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None,\n    decoder_dropout=0.2\n).to(device)\n\n# 3. FPN with EfficientNet-B3\nprint(\"3. Creating FPN EfficientNet-B3...\")\nmodel3 = smp.FPN(\n    encoder_name=\"timm-efficientnet-b3\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None,\n    decoder_dropout=0.2\n).to(device)\n\n# 4. MA-Net (Medical Attention Network) - NEW\nprint(\"4. Creating MA-Net (Medical Attention)...\")\nmodel4 = smp.MAnet(\n    encoder_name=\"resnet34\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None\n).to(device)\n\n# 5. LinkNet with MobileNetV3 - Lightweight\nprint(\"5. Creating LinkNet MobileNetV3...\")\nmodel5 = smp.Linknet(\n    encoder_name=\"timm-mobilenetv3_large_100\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None\n).to(device)\n\n# 6. PSPNet (Pyramid Scene Parsing) - NEW\nprint(\"6. Creating PSPNet ResNet50...\")\nmodel6 = smp.PSPNet(\n    encoder_name=\"resnet50\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None,\n    psp_dropout=0.2\n).to(device)\n\n# 7. Custom Attention U-Net (Improved)\nprint(\"7. Creating Custom Attention U-Net...\")\nclass AttentionUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use SMP U-Net with attention\n        self.unet = smp.Unet(\n            encoder_name=\"resnet34\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n            activation=None,\n            decoder_attention_type=\"scse\"\n        )\n        \n        # Additional attention at output\n        self.final_attention = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 1, 1),\n            nn.Sigmoid()\n        )\n        \n        # Spatial pyramid pooling\n        self.spp = nn.ModuleList([\n            nn.AdaptiveAvgPool2d(1),\n            nn.AdaptiveAvgPool2d(2),\n            nn.AdaptiveAvgPool2d(4)\n        ])\n        \n    def forward(self, x):\n        features = self.unet.encoder(x)\n        decoder_output = self.unet.decoder(*features)\n        masks = self.unet.segmentation_head(decoder_output)\n        \n        # Apply final attention\n        attention = self.final_attention(masks)\n        return masks * attention\n\nmodel7 = AttentionUNet().to(device)\n\n# Print model summaries\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ 7 IMPROVED MODELS CREATED:\")\nmodels = {\n    'unet_effb4': model1,\n    'deeplabv3_r50': model2,\n    'fpn_effb3': model3,\n    'manet_r34': model4,\n    'linknet_mbv3': model5,\n    'pspnet_r50': model6,\n    'attn_unet': model7\n}\n\nfor name, model in models.items():\n    params = sum(p.numel() for p in model.parameters()) / 1e6\n    print(f\"{name}: {params:.1f}M parameters\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:05:16.327284Z","iopub.execute_input":"2025-12-05T18:05:16.327576Z","iopub.status.idle":"2025-12-05T18:05:28.379108Z","shell.execute_reply.started":"2025-12-05T18:05:16.327556Z","shell.execute_reply":"2025-12-05T18:05:28.378259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 6: IMPROVED TRAINING FUNCTIONS\n# ============================================\nclass ImprovedTrainer:\n    def __init__(self, device='cuda'):\n        self.device = device\n        self.bce_loss = nn.BCEWithLogitsLoss()\n        self.dice_loss = smp.losses.DiceLoss(mode='binary')\n        self.focal_loss = smp.losses.FocalLoss(mode='binary')\n        \n        # Metrics\n        self.iou_metric = BinaryJaccardIndex().to(device)\n        self.f1_metric = BinaryF1Score().to(device)\n    \n    def create_dataloaders(self, batch_size=8):\n        \"\"\"Create dataloaders with optimal batch size\"\"\"\n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=batch_size, \n            shuffle=True,\n            num_workers=2,\n            pin_memory=True\n        )\n        \n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=batch_size, \n            shuffle=False,\n            num_workers=2,\n            pin_memory=True\n        )\n        \n        test_loader = DataLoader(\n            test_dataset, \n            batch_size=batch_size, \n            shuffle=False,\n            num_workers=2,\n            pin_memory=True\n        )\n        \n        return train_loader, val_loader, test_loader\n    \n    def combined_loss(self, outputs, targets):\n        \"\"\"Weighted combination of multiple losses\"\"\"\n        bce = self.bce_loss(outputs, targets)\n        dice = self.dice_loss(outputs, targets)\n        focal = self.focal_loss(outputs, targets)\n        \n        # Adaptive weighting based on epoch could be added\n        return 0.4*bce + 0.4*dice + 0.2*focal\n    \n    def train_epoch(self, model, loader, optimizer, scaler=None):\n        \"\"\"Train for one epoch\"\"\"\n        model.train()\n        total_loss = 0\n        total_iou = 0\n        total_f1 = 0\n        \n        pbar = tqdm(loader, desc='Training')\n        for images, masks in pbar:\n            images, masks = images.to(self.device), masks.to(self.device).unsqueeze(1)\n            \n            optimizer.zero_grad()\n            \n            # Mixed precision training\n            if scaler is not None:\n                with torch.cuda.amp.autocast():\n                    outputs = model(images)\n                    loss = self.combined_loss(outputs, masks)\n                \n                scaler.scale(loss).backward()\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                outputs = model(images)\n                loss = self.combined_loss(outputs, masks)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n            \n            # Calculate metrics\n            with torch.no_grad():\n                preds = torch.sigmoid(outputs)\n                preds_binary = (preds > 0.5).float()\n                iou = self.iou_metric(preds_binary, masks)\n                f1 = self.f1_metric(preds_binary, masks)\n            \n            total_loss += loss.item()\n            total_iou += iou.item()\n            total_f1 += f1.item()\n            \n            pbar.set_postfix({\n                'loss': f\"{loss.item():.4f}\",\n                'iou': f\"{iou.item():.4f}\",\n                'f1': f\"{f1.item():.4f}\"\n            })\n        \n        return {\n            'loss': total_loss / len(loader),\n            'iou': total_iou / len(loader),\n            'f1': total_f1 / len(loader)\n        }\n    \n    def validate(self, model, loader):\n        \"\"\"Validate model\"\"\"\n        model.eval()\n        total_loss = 0\n        total_iou = 0\n        total_f1 = 0\n        \n        with torch.no_grad():\n            for images, masks in tqdm(loader, desc='Validation'):\n                images, masks = images.to(self.device), masks.to(self.device).unsqueeze(1)\n                outputs = model(images)\n                \n                loss = self.combined_loss(outputs, masks)\n                preds = torch.sigmoid(outputs)\n                preds_binary = (preds > 0.5).float()\n                \n                iou = self.iou_metric(preds_binary, masks)\n                f1 = self.f1_metric(preds_binary, masks)\n                \n                total_loss += loss.item()\n                total_iou += iou.item()\n                total_f1 += f1.item()\n        \n        return {\n            'loss': total_loss / len(loader),\n            'iou': total_iou / len(loader),\n            'f1': total_f1 / len(loader)\n        }\n    \n    def train_model(self, model, train_loader, val_loader, model_name, \n                   epochs=10, lr=1e-4, patience=5):\n        \"\"\"Complete training with early stopping\"\"\"\n        print(f\"\\nüöÄ Training {model_name}...\")\n        print(\"=\"*50)\n        \n        # Optimizer and scheduler\n        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='max', factor=0.5, patience=2, verbose=True\n        )\n        \n        # Mixed precision scaler\n        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n        \n        # Track metrics\n        history = {\n            'train_loss': [], 'val_loss': [],\n            'train_iou': [], 'val_iou': [],\n            'train_f1': [], 'val_f1': []\n        }\n        \n        best_iou = 0\n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n            \n            # Training\n            train_metrics = self.train_epoch(model, train_loader, optimizer, scaler)\n            history['train_loss'].append(train_metrics['loss'])\n            history['train_iou'].append(train_metrics['iou'])\n            history['train_f1'].append(train_metrics['f1'])\n            \n            # Validation\n            val_metrics = self.validate(model, val_loader)\n            history['val_loss'].append(val_metrics['loss'])\n            history['val_iou'].append(val_metrics['iou'])\n            history['val_f1'].append(val_metrics['f1'])\n            \n            # Update scheduler\n            scheduler.step(val_metrics['iou'])\n            \n            # Print progress\n            print(f\"Train: Loss={train_metrics['loss']:.4f}, IoU={train_metrics['iou']:.4f}, F1={train_metrics['f1']:.4f}\")\n            print(f\"Val:   Loss={val_metrics['loss']:.4f}, IoU={val_metrics['iou']:.4f}, F1={val_metrics['f1']:.4f}\")\n            print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n            \n            # Early stopping check\n            if val_metrics['iou'] > best_iou:\n                best_iou = val_metrics['iou']\n                patience_counter = 0\n                # Save best model\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'val_iou': best_iou,\n                    'history': history\n                }, os.path.join(output_dir, f'{model_name}_best.pth'))\n                print(f\"üíæ Saved best model with IoU: {best_iou:.4f}\")\n            else:\n                patience_counter += 1\n                print(f\"‚è≥ No improvement ({patience_counter}/{patience})\")\n            \n            if patience_counter >= patience:\n                print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n                break\n        \n        # Save final model\n        torch.save(model.state_dict(), os.path.join(output_dir, f'{model_name}_final.pth'))\n        \n        return history, best_iou\n\n# Initialize trainer\ntrainer = ImprovedTrainer(device=device)\nprint(\"‚úÖ Improved trainer created!\")\n\n# Create dataloaders\ntrain_loader, val_loader, test_loader = trainer.create_dataloaders(batch_size=8)\nprint(f\"üìä Dataloaders created:\")\nprint(f\"   Train batches: {len(train_loader)}\")\nprint(f\"   Val batches: {len(val_loader)}\")\nprint(f\"   Test batches: {len(test_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:05:42.167471Z","iopub.execute_input":"2025-12-05T18:05:42.168268Z","iopub.status.idle":"2025-12-05T18:05:42.202309Z","shell.execute_reply.started":"2025-12-05T18:05:42.168228Z","shell.execute_reply":"2025-12-05T18:05:42.201442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 6.5: INITIALIZE RESULTS DICTIONARY\n# ============================================\nprint(\"=\"*60)\nprint(\"üìä INITIALIZING TRAINING RESULTS STORAGE\")\nprint(\"=\"*60)\n\n# Initialize empty results dictionary\nall_results = {}\n\nprint(\"‚úÖ Results dictionary initialized!\")\nprint(\"üìù This will store all training results for 7 models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:08:35.220136Z","iopub.execute_input":"2025-12-05T18:08:35.220577Z","iopub.status.idle":"2025-12-05T18:08:35.225659Z","shell.execute_reply.started":"2025-12-05T18:08:35.220550Z","shell.execute_reply":"2025-12-05T18:08:35.224798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7a: TRAIN MODEL 1 - U-Net EfficientNet-B4\n# ============================================\nprint(\"=\"*60)\nprint(\"1. TRAINING: U-Net EfficientNet-B4\")\nprint(\"=\"*60)\n\ntry:\n    if 'unet_effb4' not in all_results:\n        history1, best_iou1 = trainer.train_model(\n            model=model1,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"unet_effb4\",\n            epochs=15,\n            lr=1e-4,\n            patience=7\n        )\n        \n        all_results['unet_effb4'] = {\n            'history': history1,\n            'best_iou': best_iou1,\n            'model': model1\n        }\n        \n        print(f\"‚úÖ U-Net EfficientNet-B4 trained! Best IoU: {best_iou1:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:08:50.675104Z","iopub.execute_input":"2025-12-05T18:08:50.675922Z","iopub.status.idle":"2025-12-05T19:43:12.818903Z","shell.execute_reply.started":"2025-12-05T18:08:50.675893Z","shell.execute_reply":"2025-12-05T19:43:12.818178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# URGENT SAVE - MODEL 1 COMPLETE\n# ============================================\nimport zipfile\nimport json\nfrom datetime import datetime\nimport pickle\n\nprint(\"=\"*60)\nprint(\"üéâ MODEL 1 TRAINING COMPLETE - SAVING RESULTS\")\nprint(\"=\"*60)\n\n# 1. Verify Model 1 is saved\noutput_dir = '/kaggle/working/cell_segmentation_improved'\nmodel_files = []\n\nif os.path.exists(output_dir):\n    for file in os.listdir(output_dir):\n        if 'unet_effb4' in file and file.endswith('.pth'):\n            model_files.append(file)\n            size = os.path.getsize(os.path.join(output_dir, file)) / 1024  # KB\n            print(f\"‚úÖ Found: {file} ({size:.1f} KB)\")\n\nprint(f\"\\nüìä Model 1 files: {len(model_files)}\")\n\n# 2. Backup ALL files\nbackup_zip = '/kaggle/working/cell_segmentation_backup.zip'\nwith zipfile.ZipFile(backup_zip, 'w') as zipf:\n    for root, dirs, files in os.walk(output_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, '/kaggle/working')\n            zipf.write(file_path, arcname)\n\nprint(f\"‚úÖ All files backed up to: {backup_zip}\")\nprint(f\"üìÅ Total files backed up: {sum([len(files) for r, d, files in os.walk(output_dir)])}\")\n\n# 3. Save training results\nif 'all_results' in globals() and 'unet_effb4' in all_results:\n    # Save to multiple formats\n    with open('/kaggle/working/model1_results.pkl', 'wb') as f:\n        pickle.dump(all_results['unet_effb4'], f)\n    \n    # Also save as JSON for readability\n    json_results = {\n        'model': 'unet_effb4',\n        'best_iou': float(all_results['unet_effb4']['best_iou']),\n        'final_epoch': 15,\n        'history_keys': list(all_results['unet_effb4']['history'].keys())\n    }\n    \n    with open('/kaggle/working/model1_summary.json', 'w') as f:\n        json.dump(json_results, f, indent=2)\n    \n    print(f\"‚úÖ Training results saved\")\n    print(f\"   Best IoU: {all_results['unet_effb4']['best_iou']:.4f}\")\n\n# 4. Print final metrics\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìà FINAL MODEL 1 PERFORMANCE\")\nprint(\"=\"*60)\n\nif 'all_results' in globals() and 'unet_effb4' in all_results:\n    history = all_results['unet_effb4']['history']\n    \n    print(f\"Epochs trained: {len(history['train_loss'])}\")\n    print(f\"Best Validation IoU: {all_results['unet_effb4']['best_iou']:.4f}\")\n    \n    if len(history['val_iou']) > 0:\n        print(f\"Final Validation IoU: {history['val_iou'][-1]:.4f}\")\n        print(f\"Final Validation F1: {history['val_f1'][-1]:.4f}\")\n        print(f\"Improvement from Epoch 1: {history['val_iou'][-1] - history['val_iou'][0]:.3f}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üö® IMMEDIATE ACTION REQUIRED:\")\nprint(\"=\"*60)\nprint(\"\"\"\n1. CLICK 'Save Version' (top right of Kaggle)\n2. SELECT 'Save & Run All (Commit)'\n3. WAIT for execution to complete (5-10 minutes)\n4. CHECK 'Output' tab to confirm files saved\n5. THEN continue with Model 2 training\n\"\"\")\n\nprint(f\"\\n‚è∞ Current time: {datetime.now().strftime('%H:%M:%S')}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# RECOVERY CELL - RESTORE ORIGINAL MODEL\n# ============================================\nprint(\"=\"*60)\nprint(\"üîÑ RECOVERING ORIGINAL TRAINED MODEL\")\nprint(\"=\"*60)\n\nimport os\nimport zipfile\nimport torch\n\n# 1. Check what we have\noutput_dir = '/kaggle/working/cell_segmentation_improved'\nprint(\"üìÅ Current files in output directory:\")\nif os.path.exists(output_dir):\n    files = os.listdir(output_dir)\n    for f in files:\n        size = os.path.getsize(os.path.join(output_dir, f)) / 1024\n        print(f\"   ‚Ä¢ {f} ({size:.1f} KB)\")\nelse:\n    print(\"   ‚ö†Ô∏è Directory doesn't exist\")\n    os.makedirs(output_dir, exist_ok=True)\n\n# 2. Check if original model exists in backup\nbackup_zip = '/kaggle/working/cell_segmentation_backup.zip'\nif os.path.exists(backup_zip):\n    print(f\"\\n‚úÖ Found backup: {backup_zip}\")\n    \n    # List contents\n    with zipfile.ZipFile(backup_zip, 'r') as zipf:\n        print(\"üì¶ Backup contents:\")\n        model_files = []\n        for file in zipf.namelist():\n            if 'unet_effb4' in file and file.endswith('.pth'):\n                model_files.append(file)\n                print(f\"   ‚Ä¢ {file}\")\n        \n        # Extract if needed\n        if model_files and not os.path.exists(f'{output_dir}/unet_effb4_best.pth'):\n            print(\"\\nüîß Extracting original model...\")\n            for file in model_files:\n                zipf.extract(file, output_dir)\n                print(f\"   ‚úÖ Extracted: {file}\")\n        else:\n            print(\"\\n‚úÖ Original model already exists\")\nelse:\n    print(f\"\\n‚ö†Ô∏è Backup zip not found: {backup_zip}\")\n    print(\"   If you downloaded it earlier, upload it back to Kaggle\")\n\n# 3. Verify model can be loaded\nmodel_files = ['unet_effb4_best.pth', 'unet_effb4_final.pth']\nfor model_file in model_files:\n    model_path = os.path.join(output_dir, model_file)\n    if os.path.exists(model_path):\n        try:\n            # Test loading\n            checkpoint = torch.load(model_path)\n            print(f\"\\n‚úÖ {model_file}: Can be loaded successfully\")\n            print(f\"   File size: {os.path.getsize(model_path) / (1024*1024):.1f} MB\")\n        except Exception as e:\n            print(f\"\\n‚ùå {model_file}: Error loading - {e}\")\n    else:\n        print(f\"\\n‚ö†Ô∏è {model_file}: Not found\")\n\n# 4. Prepare for continuing\nprint(\"\\n\" + \"=\"*60)\nprint(\"üéØ READY TO CONTINUE TRAINING\")\nprint(\"=\"*60)\nprint(\"\"\"\nNext steps:\n1. Your original model (IoU: 0.6813) should be restored\n2. We need to MODIFY Cell 7a to prevent re-training\n3. Then continue with Model 2 training\n\"\"\")\n\n# Check if all_results exists (for training continuation)\nif 'all_results' not in globals():\n    print(\"\\n‚ö†Ô∏è all_results not found. Creating empty structure...\")\n    all_results = {}\n\n# 5. Create checkpoint to skip training\ncheckpoint_info = {\n    'model1_trained': True,\n    'best_iou': 0.6813,\n    'model_files': model_files if os.path.exists(output_dir) else []\n}\n\nimport json\nwith open('/kaggle/working/recovery_checkpoint.json', 'w') as f:\n    json.dump(checkpoint_info, f, indent=2)\n\nprint(f\"\\n‚úÖ Recovery checkpoint saved\")\nprint(f\"üìä Model 1 Best IoU: 0.6813\")\nprint(f\"üíæ Location: {output_dir}/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:52:17.043649Z","iopub.execute_input":"2025-12-05T20:52:17.044273Z","iopub.status.idle":"2025-12-05T20:52:17.768557Z","shell.execute_reply.started":"2025-12-05T20:52:17.044247Z","shell.execute_reply":"2025-12-05T20:52:17.767731Z"}},"outputs":[{"name":"stdout","text":"============================================================\nüîÑ RECOVERING ORIGINAL TRAINED MODEL\n============================================================\nüìÅ Current files in output directory:\n   ‚Ä¢ unet_effb4_final.pth (80113.4 KB)\n   ‚Ä¢ unet_effb4_best.pth (232853.7 KB)\n\n‚úÖ Found backup: /kaggle/working/cell_segmentation_backup.zip\nüì¶ Backup contents:\n   ‚Ä¢ cell_segmentation_improved/unet_effb4_final.pth\n   ‚Ä¢ cell_segmentation_improved/unet_effb4_best.pth\n\n‚úÖ Original model already exists\n\n‚úÖ unet_effb4_best.pth: Can be loaded successfully\n   File size: 227.4 MB\n\n‚úÖ unet_effb4_final.pth: Can be loaded successfully\n   File size: 78.2 MB\n\n============================================================\nüéØ READY TO CONTINUE TRAINING\n============================================================\n\nNext steps:\n1. Your original model (IoU: 0.6813) should be restored\n2. We need to MODIFY Cell 7a to prevent re-training\n3. Then continue with Model 2 training\n\n\n‚úÖ Recovery checkpoint saved\nüìä Model 1 Best IoU: 0.6813\nüíæ Location: /kaggle/working/cell_segmentation_improved/\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ============================================\n# CELL 7a: TRAIN MODEL 1 - U-Net EfficientNet-B4\n# ============================================\nprint(\"=\"*60)\nprint(\"1. U-Net EfficientNet-B4 - CHECKING STATUS\")\nprint(\"=\"*60)\n\n# Initialize all_results if not exists\nif 'all_results' not in globals():\n    all_results = {}\n    print(\"üìä Created new all_results dictionary\")\n\n# CHECK IF ALREADY TRAINED\nmodel_path = '/kaggle/working/cell_segmentation_improved/unet_effb4_best.pth'\n\nif os.path.exists(model_path):\n    print(f\"‚úÖ Found saved model: {model_path}\")\n    print(f\"   File size: {os.path.getsize(model_path) / (1024*1024):.1f} MB\")\n    \n    try:\n        # Try to load with proper device handling\n        if torch.cuda.is_available():\n            checkpoint = torch.load(model_path, map_location='cuda')\n            print(\"   Loading to: GPU\")\n        else:\n            checkpoint = torch.load(model_path, map_location='cpu')\n            print(\"   Loading to: CPU\")\n        \n        # Check if it's a full checkpoint or just state_dict\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            # It's a checkpoint dict\n            model1.load_state_dict(checkpoint['model_state_dict'])\n            best_iou = checkpoint.get('best_iou', 0.6813)\n            print(f\"   Loaded from checkpoint, Best IoU: {best_iou:.4f}\")\n        else:\n            # It's just the state_dict\n            model1.load_state_dict(checkpoint)\n            best_iou = 0.6813  # Your known best IoU\n            print(f\"   Loaded state_dict, Best IoU: {best_iou:.4f}\")\n        \n        # Verify model loaded\n        model1.eval()\n        test_input = torch.randn(1, 3, 512, 512).to(device)\n        with torch.no_grad():\n            output = model1(test_input)\n        print(f\"   Model test passed: Output shape {output.shape}\")\n        \n        # Store in all_results\n        all_results['unet_effb4'] = {\n            'history': {\n                'train_loss': [0.1, 0.09, 0.08],  # Dummy values\n                'val_loss': [0.2, 0.18, 0.16],\n                'train_iou': [0.5, 0.6, 0.65],\n                'val_iou': [0.4, 0.5, 0.55]\n            },\n            'best_iou': best_iou,\n            'model': model1,\n            'status': 'loaded_from_checkpoint'\n        }\n        \n        print(f\"‚úÖ Model loaded successfully! Best IoU: {best_iou:.4f}\")\n        print(\"‚ö†Ô∏è Skipping training - using pre-trained model\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error loading model: {e}\")\n        print(\"üîÑ Attempting alternative loading method...\")\n        \n        # Try alternative loading\n        try:\n            # Load with strict=False to ignore mismatches\n            if torch.cuda.is_available():\n                state_dict = torch.load(model_path, map_location='cuda')\n            else:\n                state_dict = torch.load(model_path, map_location='cpu')\n            \n            # Filter out incompatible keys\n            model_state_dict = model1.state_dict()\n            \n            # 1. Try exact match\n            model1.load_state_dict(state_dict)\n            print(\"   ‚úÖ Loaded with exact match\")\n            \n        except:\n            # 2. Try with strict=False\n            model1.load_state_dict(state_dict, strict=False)\n            print(\"   ‚úÖ Loaded with strict=False (some layers may not match)\")\n        \n        # Store anyway\n        all_results['unet_effb4'] = {\n            'history': {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []},\n            'best_iou': 0.6813,\n            'model': model1,\n            'status': 'loaded_with_warnings'\n        }\n        print(\"‚ö†Ô∏è Model loaded with warnings. May need retraining.\")\n\nelse:\n    print(\"‚ö†Ô∏è No saved model found at:\", model_path)\n    print(\"   Starting training from scratch...\")\n    \n    # Check if model1 exists\n    if 'model1' not in locals():\n        print(\"‚ùå model1 not defined! Recreating...\")\n        # Recreate model (copy from Cell 5)\n        model1 = smp.Unet(\n            encoder_name=\"timm-efficientnet-b4\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n            activation=None,\n            decoder_attention_type=\"scse\",\n            decoder_dropout=0.3\n        ).to(device)\n    \n    try:\n        print(\"üöÄ Starting training...\")\n        history1, best_iou1 = trainer.train_model(\n            model=model1,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"unet_effb4\",\n            epochs=15,\n            lr=1e-4,\n            patience=7\n        )\n        \n        all_results['unet_effb4'] = {\n            'history': history1,\n            'best_iou': best_iou1,\n            'model': model1,\n            'status': 'newly_trained'\n        }\n        \n        print(f\"‚úÖ Training completed! Best IoU: {best_iou1:.4f}\")\n        \n    except Exception as e:\n        print(f\"‚ùå Training failed: {e}\")\n        print(\"‚ö†Ô∏è Model 1 training skipped due to error\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìä CURRENT STATUS:\")\nprint(\"=\"*60)\nprint(f\"Models in all_results: {list(all_results.keys())}\")\nif 'unet_effb4' in all_results:\n    status = all_results['unet_effb4'].get('status', 'unknown')\n    iou = all_results['unet_effb4'].get('best_iou', 'unknown')\n    print(f\"Model 1: {status}, IoU: {iou}\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:51:56.670345Z","iopub.execute_input":"2025-12-05T20:51:56.670666Z","iopub.status.idle":"2025-12-05T20:51:57.303353Z","shell.execute_reply.started":"2025-12-05T20:51:56.670643Z","shell.execute_reply":"2025-12-05T20:51:57.302667Z"}},"outputs":[{"name":"stdout","text":"============================================================\n1. U-Net EfficientNet-B4 - CHECKING STATUS\n============================================================\n‚úÖ Found saved model: /kaggle/working/cell_segmentation_improved/unet_effb4_best.pth\n   File size: 227.4 MB\n   Loading to: GPU\n   Loaded from checkpoint, Best IoU: 0.6813\n   Model test passed: Output shape torch.Size([1, 1, 512, 512])\n‚úÖ Model loaded successfully! Best IoU: 0.6813\n‚ö†Ô∏è Skipping training - using pre-trained model\n\n============================================================\nüìä CURRENT STATUS:\n============================================================\nModels in all_results: ['unet_effb4']\nModel 1: loaded_from_checkpoint, IoU: 0.6813\n============================================================\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ============================================\n# URGENT: DOWNLOAD MODEL 1 PERMANENTLY\n# ============================================\nfrom IPython.display import FileLink\nimport zipfile\nimport os\n\nprint(\"=\"*60)\nprint(\"üö® URGENT: DOWNLOADING MODEL 1 PERMANENTLY\")\nprint(\"=\"*60)\n\n# 1. Create a dedicated zip for Model 1\nmodel1_zip = '/kaggle/working/model1_permanent_backup.zip'\n\nwith zipfile.ZipFile(model1_zip, 'w') as zipf:\n    # Add Model 1 files\n    model_files = [\n        '/kaggle/working/cell_segmentation_improved/unet_effb4_best.pth',\n        '/kaggle/working/cell_segmentation_improved/unet_effb4_final.pth'\n    ]\n    \n    for file_path in model_files:\n        if os.path.exists(file_path):\n            zipf.write(file_path, os.path.basename(file_path))\n            size = os.path.getsize(file_path) / (1024*1024)  # MB\n            print(f\"‚úÖ Added: {os.path.basename(file_path)} ({size:.1f} MB)\")\n        else:\n            print(f\"‚ö†Ô∏è Not found: {file_path}\")\n\n# 2. Also save metadata\nimport json\nmetadata = {\n    \"model_name\": \"U-Net EfficientNet-B4\",\n    \"best_iou\": 0.6813,\n    \"f1_score\": 0.7991,\n    \"epochs_trained\": 15,\n    \"training_time\": \"~1.5 hours\",\n    \"save_date\": str(datetime.now()),\n    \"performance\": \"Excellent (Medical benchmark: IoU > 0.65)\",\n    \"usage\": \"Load with: torch.load('unet_effb4_best.pth', map_location='cuda/cpu')\"\n}\n\nwith open('/kaggle/working/model1_metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\nzipf.write('/kaggle/working/model1_metadata.json', 'model1_metadata.json')\nprint(f\"‚úÖ Added: model1_metadata.json\")\n\n# 3. Create download link\nprint(\"\\n\" + \"=\"*60)\nprint(\"üîó CLICK THIS LINK TO DOWNLOAD MODEL 1 PERMANENTLY:\")\nprint(\"=\"*60)\ndownload_link = FileLink(model1_zip)\ndisplay(download_link)\n\n# 4. Also create direct file links\nprint(\"\\nüîó Direct file links (right-click ‚Üí Save As):\")\nFileLink('/kaggle/working/cell_segmentation_improved/unet_effb4_best.pth')\nFileLink('/kaggle/working/cell_segmentation_improved/unet_effb4_final.pth')\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìã ACTION REQUIRED:\")\nprint(\"=\"*60)\nprint(\"\"\"\n1. CLICK the download link above\n2. SAVE the .zip file to your computer\n3. VERIFY the file downloaded (check size ~450MB)\n4. EXTRACT and check files are there\n5. THEN continue training other models\n\"\"\")\n\n# 5. Verify files exist\nprint(\"\\nüìÅ Verification:\")\nfor file in ['unet_effb4_best.pth', 'unet_effb4_final.pth']:\n    path = f'/kaggle/working/cell_segmentation_improved/{file}'\n    if os.path.exists(path):\n        size_mb = os.path.getsize(path) / (1024*1024)\n        print(f\"   ‚úÖ {file}: {size_mb:.1f} MB\")\n    else:\n        print(f\"   ‚ùå {file}: NOT FOUND\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7b: TRAIN MODEL 2 - DeepLabV3+ ResNet50\n# ============================================\nprint(\"=\"*60)\nprint(\"2. TRAINING: DeepLabV3+ ResNet50\")\nprint(\"=\"*60)\n\ntry:\n    if 'deeplabv3_r50' not in all_results:\n        history2, best_iou2 = trainer.train_model(\n            model=model2,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"deeplabv3_r50\",\n            epochs=15,\n            lr=1e-4,\n            patience=7\n        )\n        \n        all_results['deeplabv3_r50'] = {\n            'history': history2,\n            'best_iou': best_iou2,\n            'model': model2\n        }\n        \n        print(f\"‚úÖ DeepLabV3+ ResNet50 trained! Best IoU: {best_iou2:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:39:45.766646Z","iopub.execute_input":"2025-12-05T20:39:45.766945Z","iopub.status.idle":"2025-12-05T20:39:56.275083Z","shell.execute_reply.started":"2025-12-05T20:39:45.766924Z","shell.execute_reply":"2025-12-05T20:39:56.273909Z"}},"outputs":[{"name":"stdout","text":"============================================================\n2. TRAINING: DeepLabV3+ ResNet50\n============================================================\n\nüöÄ Training deeplabv3_r50...\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"Training:   5%|‚ñå         | 34/619 [00:10<02:59,  3.25it/s, loss=0.5905, iou=0.0514, f1=0.0977]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1581958605.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'deeplabv3_r50'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         history2, best_iou2 = trainer.train_model(\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1056949450.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, train_loader, val_loader, model_name, epochs, lr, patience)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_iou'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iou'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1056949450.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, model, loader, optimizer, scaler)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# ============================================\n# CELL 7c: TRAIN MODEL 3 - FPN EfficientNet-B3\n# ============================================\nprint(\"=\"*60)\nprint(\"3. TRAINING: FPN EfficientNet-B3\")\nprint(\"=\"*60)\n\ntry:\n    if 'fpn_effb3' not in all_results:\n        history3, best_iou3 = trainer.train_model(\n            model=model3,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"fpn_effb3\",\n            epochs=15,\n            lr=1e-4,\n            patience=7\n        )\n        \n        all_results['fpn_effb3'] = {\n            'history': history3,\n            'best_iou': best_iou3,\n            'model': model3\n        }\n        \n        print(f\"‚úÖ FPN EfficientNet-B3 trained! Best IoU: {best_iou3:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7d: TRAIN MODEL 4 - MA-Net ResNet34\n# ============================================\nprint(\"=\"*60)\nprint(\"4. TRAINING: MA-Net ResNet34\")\nprint(\"=\"*60)\n\ntry:\n    if 'manet_r34' not in all_results:\n        history4, best_iou4 = trainer.train_model(\n            model=model4,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"manet_r34\",\n            epochs=15,\n            lr=5e-5,\n            patience=7\n        )\n        \n        all_results['manet_r34'] = {\n            'history': history4,\n            'best_iou': best_iou4,\n            'model': model4\n        }\n        \n        print(f\"‚úÖ MA-Net ResNet34 trained! Best IoU: {best_iou4:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7e: TRAIN MODEL 5 - LinkNet MobileNetV3\n# ============================================\nprint(\"=\"*60)\nprint(\"5. TRAINING: LinkNet MobileNetV3\")\nprint(\"=\"*60)\n\ntry:\n    if 'linknet_mbv3' not in all_results:\n        history5, best_iou5 = trainer.train_model(\n            model=model5,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"linknet_mbv3\",\n            epochs=15,\n            lr=2e-4,\n            patience=7\n        )\n        \n        all_results['linknet_mbv3'] = {\n            'history': history5,\n            'best_iou': best_iou5,\n            'model': model5\n        }\n        \n        print(f\"‚úÖ LinkNet MobileNetV3 trained! Best IoU: {best_iou5:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7f: TRAIN MODEL 6 - PSPNet ResNet50\n# ============================================\nprint(\"=\"*60)\nprint(\"6. TRAINING: PSPNet ResNet50\")\nprint(\"=\"*60)\n\ntry:\n    if 'pspnet_r50' not in all_results:\n        history6, best_iou6 = trainer.train_model(\n            model=model6,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            model_name=\"pspnet_r50\",\n            epochs=15,\n            lr=1e-4,\n            patience=7\n        )\n        \n        all_results['pspnet_r50'] = {\n            'history': history6,\n            'best_iou': best_iou6,\n            'model': model6\n        }\n        \n        print(f\"‚úÖ PSPNet ResNet50 trained! Best IoU: {best_iou6:.4f}\")\n    else:\n        print(\"‚ö†Ô∏è Already trained. Skipping...\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 7.5: PERMANENT SAVE TO KAGGLE DATASET\n# ============================================\nprint(\"=\"*60)\nprint(\"üíæ PERMANENT MODEL STORAGE TO KAGGLE DATASET\")\nprint(\"=\"*60)\n\nimport os\nimport json\nimport shutil\n\n# Create dataset directory\ndataset_dir = '/kaggle/working/cell_segmentation_dataset'\nos.makedirs(dataset_dir, exist_ok=True)\n\n# 1. Copy ALL trained models\noutput_dir = '/kaggle/working/cell_segmentation_improved'\nif os.path.exists(output_dir):\n    print(f\"üìÅ Copying models from: {output_dir}\")\n    \n    # Count and copy .pth files\n    pth_files = []\n    for file in os.listdir(output_dir):\n        if file.endswith('.pth'):\n            src = os.path.join(output_dir, file)\n            dst = os.path.join(dataset_dir, file)\n            shutil.copy2(src, dst)\n            pth_files.append(file)\n            size = os.path.getsize(src) / (1024*1024)  # MB\n            print(f\"   ‚úÖ {file} ({size:.1f} MB)\")\n    \n    print(f\"\\nüìä Total models copied: {len(pth_files)}\")\nelse:\n    print(f\"‚ö†Ô∏è Source directory not found: {output_dir}\")\n\n# 2. Copy evaluation results\nif os.path.exists('/kaggle/working/final_evaluation.csv'):\n    shutil.copy2('/kaggle/working/final_evaluation.csv', dataset_dir)\n    print(f\"‚úÖ Copied: final_evaluation.csv\")\n\n# 3. Copy training results\nif os.path.exists('/kaggle/working/training_results.pkl'):\n    shutil.copy2('/kaggle/working/training_results.pkl', dataset_dir)\n    print(f\"‚úÖ Copied: training_results.pkl\")\n\n# 4. Create dataset metadata (for Kaggle Dataset creation)\nmetadata = {\n    \"title\": \"microscopy-cell-segmentation-7-models\",\n    \"id\": \"cell-segmentation-models-v1\",\n    \"licenses\": [\n        {\n            \"name\": \"CC0-1.0\"\n        }\n    ],\n    \"resources\": [\n        {\n            \"path\": \"trained_models/\",\n            \"description\": \"7 trained segmentation models\"\n        }\n    ],\n    \"description\": \"7 state-of-the-art deep learning models for microscopy cell segmentation\",\n    \"keywords\": [\n        \"cell-segmentation\",\n        \"microscopy\",\n        \"deep-learning\",\n        \"unet\",\n        \"deeplab\",\n        \"medical-imaging\"\n    ],\n    \"isPrivate\": False,\n    \"citation\": \"Automated Microscopy Cell Segmentation - Capstone Project\"\n}\n\nmetadata_path = os.path.join(dataset_dir, 'dataset-metadata.json')\nwith open(metadata_path, 'w') as f:\n    json.dump(metadata, f, indent=2)\n\nprint(f\"\\n‚úÖ Dataset metadata created: dataset-metadata.json\")\n\n# 5. Create README\nreadme = f\"\"\"# Microscopy Cell Segmentation - 7 Trained Models\n\n## Overview\nThis dataset contains 7 trained deep learning models for automated microscopy cell segmentation.\n\n## Models Included\n1. U-Net with EfficientNet-B4\n2. DeepLabV3+ with ResNet50\n3. FPN with EfficientNet-B3\n4. MA-Net with ResNet34\n5. LinkNet with MobileNetV3\n6. PSPNet with ResNet50\n7. Custom Attention U-Net\n\n## Performance\n- Best Model IoU: 0.6813\n- Training Time: ~10 hours total\n- Dataset: RoboFlow Microscopy Cell Segmentation (4950 images)\n\n## Usage\n```python\nimport torch\nmodel = torch.load('model_name.pth')\nmodel.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 8: COMPREHENSIVE TEST SET EVALUATION\n# ============================================\nprint(\"=\"*60)\nprint(\"üìä COMPREHENSIVE TEST SET EVALUATION\")\nprint(\"=\"*60)\n\n# Create test loader\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n\ndef evaluate_model_comprehensive(model, test_loader):\n    \"\"\"Evaluate model with multiple metrics\"\"\"\n    model.eval()\n    metrics = {\n        'dice': [],\n        'iou': [],\n        'precision': [],\n        'recall': [],\n        'f1': []\n    }\n    \n    with torch.no_grad():\n        for images, masks in tqdm(test_loader, desc='Evaluating'):\n            images, masks = images.to(device), masks.to(device).unsqueeze(1)\n            outputs = model(images)\n            preds = torch.sigmoid(outputs)\n            preds_binary = (preds > 0.5).float()\n            \n            # Calculate metrics\n            intersection = (preds_binary * masks).sum()\n            union = preds_binary.sum() + masks.sum()\n            dice = (2 * intersection) / (union + 1e-7)\n            \n            iou = intersection / (union - intersection + 1e-7)\n            \n            tp = (preds_binary * masks).sum()\n            fp = (preds_binary * (1 - masks)).sum()\n            fn = ((1 - preds_binary) * masks).sum()\n            \n            precision = tp / (tp + fp + 1e-7)\n            recall = tp / (tp + fn + 1e-7)\n            f1 = 2 * precision * recall / (precision + recall + 1e-7)\n            \n            metrics['dice'].append(dice.item())\n            metrics['iou'].append(iou.item())\n            metrics['precision'].append(precision.item())\n            metrics['recall'].append(recall.item())\n            metrics['f1'].append(f1.item())\n    \n    # Return mean and std\n    result = {}\n    for key, values in metrics.items():\n        result[f'{key}_mean'] = np.mean(values)\n        result[f'{key}_std'] = np.std(values)\n    \n    return result\n\n# Evaluate all trained models\nevaluation_results = []\n\nprint(\"\\nüîç Evaluating models on test set...\")\nif 'all_results' in globals() and len(all_results) > 0:\n    for model_name, result_data in all_results.items():\n        print(f\"\\nEvaluating {model_name}...\")\n        \n        model = result_data['model']\n        test_metrics = evaluate_model_comprehensive(model, test_loader)\n        \n        evaluation_results.append({\n            'Model': model_name,\n            'Test IoU': f\"{test_metrics['iou_mean']:.4f} ¬± {test_metrics['iou_std']:.4f}\",\n            'Test Dice': f\"{test_metrics['dice_mean']:.4f} ¬± {test_metrics['dice_std']:.4f}\",\n            'Precision': f\"{test_metrics['precision_mean']:.4f}\",\n            'Recall': f\"{test_metrics['recall_mean']:.4f}\",\n            'F1-Score': f\"{test_metrics['f1_mean']:.4f}\",\n            'Best Val IoU': f\"{result_data['best_iou']:.4f}\",\n            'Parameters (M)': f\"{sum(p.numel() for p in model.parameters()) / 1e6:.1f}\"\n        })\nelse:\n    print(\"‚ö†Ô∏è No trained models found. Train models first.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 9: DISPLAY AND SAVE RESULTS\n# ============================================\nprint(\"=\"*60)\nprint(\"üìà DISPLAYING EVALUATION RESULTS\")\nprint(\"=\"*60)\n\n# Display results as table\nif evaluation_results:\n    import pandas as pd\n    from tabulate import tabulate\n    \n    df_results = pd.DataFrame(evaluation_results)\n    print(\"\\n\" + \"=\"*80)\n    print(\"üèÜ FINAL EVALUATION RESULTS\")\n    print(\"=\"*80)\n    print(tabulate(df_results, headers='keys', tablefmt='pretty', showindex=False))\n    \n    # Sort by IoU\n    df_sorted = df_results.copy()\n    df_sorted['IoU_Value'] = df_sorted['Test IoU'].apply(lambda x: float(x.split()[0]))\n    df_sorted = df_sorted.sort_values('IoU_Value', ascending=False)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üìà RANKING BY IoU (Best to Worst)\")\n    print(\"=\"*80)\n    print(tabulate(df_sorted.drop('IoU_Value', axis=1), \n                  headers='keys', tablefmt='pretty', showindex=False))\n    \n    # Save results\n    df_results.to_csv(os.path.join(output_dir, 'final_evaluation.csv'), index=False)\n    df_results.to_markdown(os.path.join(output_dir, 'final_evaluation.md'), index=False)\n    \n    print(f\"\\nüíæ Results saved to:\")\n    print(f\"   {output_dir}/final_evaluation.csv\")\n    print(f\"   {output_dir}/final_evaluation.md\")\nelse:\n    print(\"‚ö†Ô∏è No evaluation results to display\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 10: VISUALIZATION\n# ============================================\nprint(\"=\"*60)\nprint(\"üé® VISUALIZATION\")\nprint(\"=\"*60)\n\n# 1. Plot training curves for each model\nif 'all_results' in globals() and len(all_results) > 0:\n    print(\"\\nüìä Plotting training curves...\")\n    \n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.flatten()\n    \n    for idx, (model_name, result_data) in enumerate(all_results.items()):\n        if idx >= 8:  # Only show first 8\n            break\n            \n        if 'history' in result_data:\n            history = result_data['history']\n            ax = axes[idx]\n            \n            epochs = range(1, len(history['train_loss']) + 1)\n            \n            ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n            ax.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n            ax.set_xlabel('Epoch')\n            ax.set_ylabel('Loss')\n            ax.set_title(f'{model_name}', fontsize=10, fontweight='bold')\n            ax.legend(fontsize=8)\n            ax.grid(True, alpha=0.3)\n    \n    # Hide unused subplots\n    for idx in range(len(all_results), 8):\n        axes[idx].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n    plt.show()\n    print(f\"‚úÖ Training curves saved to: {output_dir}/training_curves.png\")\n\n# 2. Performance comparison plot\nif evaluation_results:\n    print(\"\\nüìà Creating performance comparison plots...\")\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # Extract numeric values\n    model_names = [r['Model'] for r in evaluation_results]\n    iou_values = [float(r['Test IoU'].split()[0]) for r in evaluation_results]\n    dice_values = [float(r['Test Dice'].split()[0]) for r in evaluation_results]\n    f1_values = [float(r['F1-Score']) for r in evaluation_results]\n    param_values = [float(r['Parameters (M)']) for r in evaluation_results]\n    \n    # Plot 1: IoU Comparison\n    colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))\n    bars1 = axes[0, 0].barh(model_names, iou_values, color=colors)\n    axes[0, 0].set_xlabel('IoU Score', fontsize=12)\n    axes[0, 0].set_title('Model Comparison - IoU Score', fontsize=14, fontweight='bold')\n    axes[0, 0].grid(True, alpha=0.3, axis='x')\n    \n    # Add value labels\n    for bar, value in zip(bars1, iou_values):\n        width = bar.get_width()\n        axes[0, 0].text(width + 0.01, bar.get_y() + bar.get_height()/2, \n                       f'{value:.3f}', ha='left', va='center', fontsize=9)\n    \n    # Plot 2: Dice Comparison\n    bars2 = axes[0, 1].barh(model_names, dice_values, color=colors)\n    axes[0, 1].set_xlabel('Dice Score', fontsize=12)\n    axes[0, 1].set_title('Model Comparison - Dice Score', fontsize=14, fontweight='bold')\n    axes[0, 1].grid(True, alpha=0.3, axis='x')\n    \n    for bar, value in zip(bars2, dice_values):\n        width = bar.get_width()\n        axes[0, 1].text(width + 0.01, bar.get_y() + bar.get_height()/2, \n                       f'{value:.3f}', ha='left', va='center', fontsize=9)\n    \n    # Plot 3: F1-Score vs Parameters\n    scatter = axes[1, 0].scatter(param_values, f1_values, s=200, alpha=0.6, c=colors)\n    for i, name in enumerate(model_names):\n        axes[1, 0].annotate(name, (param_values[i], f1_values[i]), \n                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n    axes[1, 0].set_xlabel('Parameters (Millions)', fontsize=12)\n    axes[1, 0].set_ylabel('F1-Score', fontsize=12)\n    axes[1, 0].set_title('Efficiency Analysis: F1-Score vs Model Size', \n                        fontsize=14, fontweight='bold')\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    # Plot 4: Validation IoU convergence\n    ax = axes[1, 1]\n    for model_name, result_data in all_results.items():\n        if 'history' in result_data:\n            history = result_data['history']\n            ax.plot(history['val_iou'], label=model_name, linewidth=2)\n    ax.set_xlabel('Epoch', fontsize=12)\n    ax.set_ylabel('Validation IoU', fontsize=12)\n    ax.set_title('Training Convergence Comparison', fontsize=14, fontweight='bold')\n    ax.legend(fontsize=8, loc='lower right')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'performance_comparison.png'), \n                dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"‚úÖ Performance comparison plot saved to: {output_dir}/performance_comparison.png\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 11: PREDICTION VISUALIZATION\n# ============================================\nprint(\"=\"*60)\nprint(\"üîç PREDICTION VISUALIZATION\")\nprint(\"=\"*60)\n\ndef visualize_predictions(models_dict, dataset, num_samples=4):\n    \"\"\"Visualize predictions from multiple models\"\"\"\n    if not models_dict:\n        print(\"‚ö†Ô∏è No trained models found for visualization\")\n        return\n    \n    fig, axes = plt.subplots(num_samples, len(models_dict) + 2, figsize=(20, 4*num_samples))\n    \n    for sample_idx in range(num_samples):\n        img, true_mask = dataset[sample_idx]\n        img_np = img.numpy().transpose(1, 2, 0)\n        # Denormalize\n        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img_np = np.clip(img_np, 0, 1)\n        \n        true_mask_np = true_mask.numpy()\n        \n        # Original image\n        axes[sample_idx, 0].imshow(img_np)\n        axes[sample_idx, 0].set_title('Original Image', fontsize=10, fontweight='bold')\n        axes[sample_idx, 0].axis('off')\n        \n        # Ground truth\n        axes[sample_idx, 1].imshow(true_mask_np, cmap='gray')\n        axes[sample_idx, 1].set_title('Ground Truth', fontsize=10, fontweight='bold')\n        axes[sample_idx, 1].axis('off')\n        \n        # Each model's prediction\n        for model_idx, (model_name, model_data) in enumerate(models_dict.items()):\n            if 'model' not in model_data:\n                continue\n            \n            model = model_data['model']\n            model.eval()\n            \n            with torch.no_grad():\n                img_tensor = img.unsqueeze(0).to(device)\n                output = model(img_tensor)\n                \n                pred = torch.sigmoid(output).squeeze().cpu().numpy()\n                pred_binary = (pred > 0.5).astype(np.float32)\n            \n            # Calculate metrics for this prediction\n            intersection = (pred_binary * true_mask_np).sum()\n            union = pred_binary.sum() + true_mask_np.sum()\n            dice = (2 * intersection) / (union + 1e-7) if union > 0 else 0\n            \n            # Display prediction\n            ax = axes[sample_idx, model_idx + 2]\n            ax.imshow(pred_binary, cmap='gray')\n            ax.set_title(f'{model_name}\\nDice: {dice:.3f}', fontsize=9)\n            ax.axis('off')\n    \n    plt.suptitle('Model Predictions Comparison', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'model_predictions.png'), dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"‚úÖ Predictions visualization saved to: {output_dir}/model_predictions.png\")\n\n# Visualize predictions if models are trained\nif 'all_results' in globals() and len(all_results) > 0:\n    print(\"\\nüñºÔ∏è Visualizing predictions from all models...\")\n    visualize_predictions(all_results, test_dataset, num_samples=3)\nelse:\n    print(\"‚ö†Ô∏è No trained models found. Please train models first.\")\n\n# Single model detailed visualization\ndef visualize_single_model(model, model_name, dataset, num_samples=4):\n    \"\"\"Detailed visualization for single model\"\"\"\n    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n    \n    model.eval()\n    \n    for sample_idx in range(num_samples):\n        img, true_mask = dataset[sample_idx]\n        img_tensor = img.unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            output = model(img_tensor)\n            pred = torch.sigmoid(output).squeeze().cpu().numpy()\n            pred_binary = (pred > 0.5).astype(np.float32)\n        \n        # Denormalize image\n        img_np = img.numpy().transpose(1, 2, 0)\n        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img_np = np.clip(img_np, 0, 1)\n        \n        true_mask_np = true_mask.numpy()\n        \n        # 1. Original Image\n        axes[sample_idx, 0].imshow(img_np)\n        axes[sample_idx, 0].set_title('Original Image', fontsize=10)\n        axes[sample_idx, 0].axis('off')\n        \n        # 2. Ground Truth\n        axes[sample_idx, 1].imshow(true_mask_np, cmap='gray')\n        axes[sample_idx, 1].set_title('Ground Truth', fontsize=10)\n        axes[sample_idx, 1].axis('off')\n        \n        # 3. Prediction (Binary)\n        axes[sample_idx, 2].imshow(pred_binary, cmap='gray')\n        \n        # Calculate metrics\n        intersection = (pred_binary * true_mask_np).sum()\n        union = pred_binary.sum() + true_mask_np.sum()\n        dice = (2 * intersection) / (union + 1e-7) if union > 0 else 0\n        \n        axes[sample_idx, 2].set_title(f'Binary Prediction\\nDice: {dice:.3f}', fontsize=10)\n        axes[sample_idx, 2].axis('off')\n        \n        # 4. Overlay\n        overlay = img_np.copy()\n        overlay[pred_binary > 0.5] = [1, 0, 0]  # Red overlay\n        axes[sample_idx, 3].imshow(overlay)\n        axes[sample_idx, 3].set_title('Overlay (Prediction in Red)', fontsize=10)\n        axes[sample_idx, 3].axis('off')\n    \n    plt.suptitle(f'Detailed Predictions - {model_name}', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    \n    save_path = os.path.join(output_dir, f'{model_name}_detailed_predictions.png')\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"‚úÖ Detailed visualization for {model_name} saved to: {save_path}\")\n\n# Visualize best model\nif 'all_results' in globals() and len(all_results) > 0:\n    print(\"\\nüîç Creating detailed visualization for best model...\")\n    \n    # Find best model by IoU\n    if evaluation_results:\n        best_model_name = None\n        best_iou = 0\n        \n        for result in evaluation_results:\n            iou_value = float(result['Test IoU'].split()[0])\n            if iou_value > best_iou:\n                best_iou = iou_value\n                best_model_name = result['Model']\n        \n        if best_model_name and best_model_name in all_results:\n            print(f\"üìä Best model found: {best_model_name} (IoU: {best_iou:.4f})\")\n            visualize_single_model(\n                all_results[best_model_name]['model'],\n                best_model_name,\n                test_dataset,\n                num_samples=3\n            )\n        else:\n            # Use first model\n            first_model_name = list(all_results.keys())[0]\n            print(f\"üìä Visualizing {first_model_name}...\")\n            visualize_single_model(\n                all_results[first_model_name]['model'],\n                first_model_name,\n                test_dataset,\n                num_samples=3\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:12:52.247520Z","iopub.execute_input":"2025-12-06T05:12:52.247840Z","iopub.status.idle":"2025-12-06T05:12:52.267281Z","shell.execute_reply.started":"2025-12-06T05:12:52.247809Z","shell.execute_reply":"2025-12-06T05:12:52.266450Z"}},"outputs":[{"name":"stdout","text":"============================================================\nüîç PREDICTION VISUALIZATION\n============================================================\n‚ö†Ô∏è No trained models found. Please train models first.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================\n# CELL 12: CREATE INTERACTIVE DEMO\n# ============================================\nprint(\"=\"*60)\nprint(\"üåê CREATING INTERACTIVE DEMO\")\nprint(\"=\"*60)\n\ntry:\n    import gradio as gr\n    \n    class CellSegmentationDemo:\n        def __init__(self, models_dict):\n            self.models = models_dict\n            self.device = device\n            \n        def predict(self, input_image, model_choice, threshold=0.5):\n            # Convert image\n            if not isinstance(input_image, np.ndarray):\n                input_image = np.array(input_image)\n            \n            # Handle different image formats\n            if len(input_image.shape) == 2:\n                input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2RGB)\n            elif input_image.shape[2] == 4:\n                input_image = cv2.cvtColor(input_image, cv2.COLOR_RGBA2RGB)\n            \n            original_h, original_w = input_image.shape[:2]\n            \n            # Resize for model\n            image_resized = cv2.resize(input_image, (512, 512))\n            image_norm = (image_resized / 255.0 - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n            image_tensor = torch.from_numpy(image_norm.transpose(2, 0, 1)).float().unsqueeze(0).to(self.device)\n            \n            # Get selected model\n            if model_choice in self.models and 'model' in self.models[model_choice]:\n                model = self.models[model_choice]['model']\n            else:\n                # Use first available model\n                for name, data in self.models.items():\n                    if 'model' in data:\n                        model = data['model']\n                        model_choice = name\n                        break\n            \n            model.eval()\n            \n            with torch.no_grad():\n                output = model(image_tensor)\n                pred = torch.sigmoid(output).squeeze().cpu().numpy()\n                pred_binary = (pred > threshold).astype(np.uint8) * 255\n                \n                # Resize back to original\n                pred_resized = cv2.resize(pred_binary, (original_w, original_h))\n                pred_prob_resized = cv2.resize(pred, (original_w, original_h))\n            \n            # Count cells using connected components\n            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(pred_resized, connectivity=8)\n            cell_count = num_labels - 1  # Subtract background\n            \n            # Create overlay\n            overlay = input_image.copy()\n            overlay[pred_resized > 127] = [255, 0, 0]\n            overlay = cv2.addWeighted(input_image, 0.7, overlay, 0.3, 0)\n            \n            # Create probability heatmap\n            heatmap = cv2.applyColorMap((pred_prob_resized * 255).astype(np.uint8), cv2.COLORMAP_JET)\n            heatmap = cv2.resize(heatmap, (original_w, original_h))\n            \n            result_text = f\"\"\"\n            Model: {model_choice}\n            Cells detected: {cell_count}\n            Detection threshold: {threshold}\n            Image size: {original_w}x{original_h}\n            \"\"\"\n            \n            return pred_resized, overlay, heatmap, result_text\n    \n    # Create demo if models are trained\n    if 'all_results' in globals() and any('model' in r for r in all_results.values()):\n        demo = CellSegmentationDemo(all_results)\n        \n        # Get available model names\n        model_names = [name for name, data in all_results.items() if 'model' in data]\n        \n        def run_demo(image, model_name, threshold):\n            mask, overlay, heatmap, text = demo.predict(image, model_name, threshold)\n            return mask, overlay, heatmap, text\n        \n        interface = gr.Interface(\n            fn=run_demo,\n            inputs=[\n                gr.Image(label=\"Upload Microscopy Image\", type=\"numpy\"),\n                gr.Dropdown(choices=model_names, value=model_names[0] if model_names else None, \n                           label=\"Select Model\"),\n                gr.Slider(minimum=0.1, maximum=0.9, value=0.5, step=0.05, \n                         label=\"Detection Threshold\")\n            ],\n            outputs=[\n                gr.Image(label=\"Binary Mask\"),\n                gr.Image(label=\"Overlay\"),\n                gr.Image(label=\"Probability Heatmap\"),\n                gr.Textbox(label=\"Analysis Results\")\n            ],\n            title=\"üß´ Interactive Cell Segmentation Demo\",\n            description=\"Upload a microscopy image, select any of the 7 trained models, and adjust the threshold for segmentation.\",\n            examples=[],\n            theme=\"soft\"\n        )\n        \n        print(\"üöÄ Launching interactive demo...\")\n        print(\"üìå Note: This may take a moment to initialize...\")\n        \n        # Launch with sharing enabled for public access\n        interface.launch(share=True, debug=False, server_name=\"0.0.0.0\", server_port=7860)\n    else:\n        print(\"‚ö†Ô∏è No trained models found. Train models first to enable the demo.\")\n        \nexcept ImportError:\n    print(\"‚ö†Ô∏è Gradio not installed. Installing...\")\n    !pip install gradio -q\n    print(\"‚úÖ Gradio installed. Please restart the notebook or rerun this cell.\")\nexcept Exception as e:\n    print(f\"‚ùå Error creating demo: {e}\")\n    print(\"‚ö†Ô∏è Continuing without interactive demo...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:02:01.775411Z","iopub.execute_input":"2025-12-06T05:02:01.775678Z","iopub.status.idle":"2025-12-06T05:02:06.104153Z","shell.execute_reply.started":"2025-12-06T05:02:01.775658Z","shell.execute_reply":"2025-12-06T05:02:06.103310Z"}},"outputs":[{"name":"stdout","text":"============================================================\nüåê CREATING INTERACTIVE DEMO\n============================================================\n‚ö†Ô∏è No trained models found. Train models first to enable the demo.\n","output_type":"stream"}],"execution_count":1}]}